{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simplified Retrieval Augmented Generation (RAG) Demonstration\n",
        "\n",
        "This is based on: https://www.youtube.com/watch?v=P8tOjiYEFqU&ab_channel=DonWoodlock\n",
        "\n",
        "\"\"\"\n",
        "This demonstration illustrates the ease of implementing Retrieval Augmented Generation (RAG) using ChatGPT's built-in capabilities.\n",
        "We'll construct a minimal, or \"micro,\" dataset to serve as the knowledge base for our Language Model (LLM).\n",
        "The core concept of RAG involves retrieving relevant information from this external dataset based on the user's query and\n",
        "incorporating it into the LLM's response. We will also visualize the similarity between the query and dataset embeddings\n",
        "using the dot product, highlighting how proximity in embedding space correlates with semantic relevance.\n",
        "\n",
        "Key Concepts:\n",
        "\n",
        "* **RAG (Retrieval Augmented Generation):** A technique that enhances LLMs by allowing them to access and incorporate information from external knowledge sources.\n",
        "  This improves accuracy and reduces hallucinations by grounding responses in real data.\n",
        "* **Embeddings:** Numerical representations of text, capturing semantic meaning. These are vectors in a high-dimensional space where similar texts have closer vectors.\n",
        "* **Dot Product Similarity:** A measure of similarity between two vectors. In the context of embeddings, a higher dot product indicates greater similarity.\n",
        "  The dot product of two vectors $\\mathbf{a}$ and $\\mathbf{b}$ is calculated as:\n",
        "    $$ \\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^{n} a_i b_i $$\n",
        "    where $n$ is the dimension of the vectors.\n",
        "* **Visualization:** We will plot the dot product results to visually represent the similarity scores, aiding in understanding how the query's embedding relates to the dataset embeddings.\n",
        "\n",
        "Detailed Steps:\n",
        "\n",
        "1.  **Environment Setup and API Configuration:**\n",
        "    * Install necessary Python libraries, including `openai` for accessing the OpenAI API and potentially `numpy` and `matplotlib` for numerical operations and plotting.\n",
        "    * Configure the OpenAI API key to enable communication with the API. This typically involves setting an environment variable or loading the key from a configuration file.\n",
        "2.  **Dataset Embedding Generation:**\n",
        "    * Create a small dataset of text snippets.\n",
        "    * Utilize the OpenAI API's embedding model (e.g., `text-embedding-ada-002`) to generate embeddings for each text snippet in the dataset.\n",
        "      This transforms the text into numerical vectors. Store these embeddings along with the corresponding text.\n",
        "3.  **Query Embedding Generation:**\n",
        "    * Formulate a user query.\n",
        "    * Generate the embedding for the query using the same embedding model used for the dataset. This ensures consistency in the embedding space.\n",
        "4.  **Similarity Calculation and Visualization:**\n",
        "    * Calculate the dot product between the query embedding and each dataset embedding. This yields a similarity score for each dataset entry.\n",
        "    * Store the similarity scores.\n",
        "    * Visualize the similarity scores. This can be done by creating a bar plot, where the x-axis represents the dataset entries, and the y-axis represents the dot product similarity scores.\n",
        "      This visualization will clearly show which dataset entries are most relevant to the query.\n",
        "5.  **RAG Integration:**\n",
        "    * Provide the LLM with the user query, and the most relevant information retrieved from the dataset, based on the highest dot product scores.\n",
        "    * Instruct the LLM to use the retrieved information to generate a response.\n",
        "    * Observe the response generated by the LLM, noting how the retrieved information influences the output.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JOKaVSFtdJBG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mNKKV-2a-bMQ",
        "outputId": "c0543024-a590-4273-c7bd-ea6b07a413a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas is already installed.\n",
            "openai is already installed.\n",
            "numpy is already installed.\n",
            "pdp is already installed.\n",
            "All necessary libraries are installed.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries if they are not already installed.\n",
        "# We will check if the libraries are installed, and install them if they are not.\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "    print(\"pandas is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"pandas is not installed. Installing...\")\n",
        "    !pip install pandas\n",
        "    import pandas as pd\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    print(\"openai is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"openai is not installed. Installing...\")\n",
        "    !pip install openai\n",
        "    from openai import OpenAI\n",
        "    import openai\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "    print(\"numpy is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"numpy is not installed. Installing...\")\n",
        "    !pip install numpy\n",
        "    import numpy as np\n",
        "\n",
        "try:\n",
        "    import pdp\n",
        "    print(\"pdp is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"pdp is not installed. Installing...\")\n",
        "    !pip install pdp\n",
        "    import pdp\n",
        "\n",
        "# os and ast are standard library modules and should be available without pip install.\n",
        "import os\n",
        "import ast\n",
        "\n",
        "print(\"All necessary libraries are installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate OpenAI Api and api key\n",
        "client = OpenAI()\n",
        "openai.api_key = ''# Add your own key"
      ],
      "metadata": {
        "id": "vxKn5ZYJMHrg"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User query (real-time information request - ChatGPT will likely refuse)\n",
        "question = \"How is the weather in Darbhanga on Monday, 7th?\""
      ],
      "metadata": {
        "id": "lZHt0HaX-qMu"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the pre-saved 10-day weather data for Darbhanga, which will serve as context.\n",
        "weather_data_path = \"/darbhanga_weather.txt\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(weather_data_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Weather data file not found at '{weather_data_path}'.\")\n",
        "    exit()  # Or handle the error appropriately\n",
        "\n",
        "# Convert each row of the DataFrame into a comma-separated string for context.\n",
        "context = [\", \".join(row.astype(str)) for _, row in df.iterrows()]\n",
        "\n",
        "# Display the first two context strings for quick verification.\n",
        "print(\"First context string:\", context[0])\n",
        "print(\"Second context string:\", context[1])\n",
        "\n",
        "# Print the entire context list (for debugging or inspection).\n",
        "print(\"\\nFull context list:\", context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOkESxa5Xmv_",
        "outputId": "317b762f-4025-480f-8e64-3fccaccacc1a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First context string: Tue 01,  Sunny,  37°/19°,  1%,  SW 9 mph, nan\n",
            "Second context string: Wed 02,  Mostly Cloudy,  35°/22°,  0%,  WSW 10 mph, nan\n",
            "\n",
            "Full context list: ['Tue 01,  Sunny,  37°/19°,  1%,  SW 9 mph, nan', 'Wed 02,  Mostly Cloudy,  35°/22°,  0%,  WSW 10 mph, nan', 'Thu 03,  Cloudy,  35°/22°,  0%,  W 11 mph, nan', 'Fri 04,  Mostly Sunny,  36°/21°,  1%,  W 13 mph, nan', 'Sat 05,  Sunny,  37°/21°,  1%,  W 11 mph, nan', 'Sun 06,  Sunny,  37°/23°,  1%,  SSE 7 mph, nan', 'Mon 07,  Sunny,  37°/25°,  2%,  ESE 13 mph, nan', 'Tue 08,  Mostly Sunny,  38°/24°,  4%,  E 13 mph, nan', 'Wed 09,  Mostly Sunny,  37°/24°,  7%,  E 10 mph, nan', 'Thu 10,  Mostly Sunny,  36°/23°,  17%,  E 13 mph, nan', 'Fri 11,  Partly Cloudy,  35°/23°,  15%,  E 13 mph, nan', 'Sat 12,  Isolated T-Storms,  34°/23°,  32%,  E 11 mph, nan', 'Sun 13,  Partly Cloudy,  34°/23°,  24%,  E 11 mph, nan', 'Mon 14,  Partly Cloudy,  35°/24°,  16%,  E 10 mph, nan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the weather data from the CSV file.\n",
        "df = pd.read_csv(\"/darbhanga_weather.txt\")\n",
        "\n",
        "# Create a new 'text_data' column by converting each row into a comma-separated string.\n",
        "df['text_data'] = df.apply(lambda row: \", \".join(row.astype(str)), axis=1)\n",
        "\n",
        "# Display the 'text_data' column.\n",
        "print(df[['text_data']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VomXfEBZZvzU",
        "outputId": "87e0ff50-044e-4a60-d90f-9d40e2da4fec"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            text_data\n",
            "0       Tue 01,  Sunny,  37°/19°,  1%,  SW 9 mph, nan\n",
            "1   Wed 02,  Mostly Cloudy,  35°/22°,  0%,  WSW 10...\n",
            "2      Thu 03,  Cloudy,  35°/22°,  0%,  W 11 mph, nan\n",
            "3   Fri 04,  Mostly Sunny,  36°/21°,  1%,  W 13 mp...\n",
            "4       Sat 05,  Sunny,  37°/21°,  1%,  W 11 mph, nan\n",
            "5      Sun 06,  Sunny,  37°/23°,  1%,  SSE 7 mph, nan\n",
            "6     Mon 07,  Sunny,  37°/25°,  2%,  ESE 13 mph, nan\n",
            "7   Tue 08,  Mostly Sunny,  38°/24°,  4%,  E 13 mp...\n",
            "8   Wed 09,  Mostly Sunny,  37°/24°,  7%,  E 10 mp...\n",
            "9   Thu 10,  Mostly Sunny,  36°/23°,  17%,  E 13 m...\n",
            "10  Fri 11,  Partly Cloudy,  35°/23°,  15%,  E 13 ...\n",
            "11  Sat 12,  Isolated T-Storms,  34°/23°,  32%,  E...\n",
            "12  Sun 13,  Partly Cloudy,  34°/23°,  24%,  E 11 ...\n",
            "13  Mon 14,  Partly Cloudy,  35°/24°,  16%,  E 10 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI client (ensure your API key is set in the environment)\n",
        "client = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
        "    \"\"\"\n",
        "    Generates an embedding for the given text using the specified OpenAI embedding model.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to be embedded.\n",
        "        model (str, optional): The OpenAI embedding model to use. Defaults to \"text-embedding-3-small\".\n",
        "\n",
        "    Returns:\n",
        "        list: The embedding vector as a list of floats.\n",
        "    \"\"\"\n",
        "    # Replace newlines with spaces to avoid potential issues with the API\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "\n",
        "    # Print the input text (for debugging or logging purposes)\n",
        "    print(f\"Generating embedding for: '{text}'\")\n",
        "\n",
        "    # Generate the embedding using the OpenAI API\n",
        "    try:\n",
        "      embedding_response = client.embeddings.create(input=[text], model=model)\n",
        "      embedding = embedding_response.data[0].embedding\n",
        "      return embedding\n",
        "    except Exception as e:\n",
        "      print(f\"An error occurred while generating embedding: {e}\")\n",
        "      return None # or raise the exception.\n",
        "\n",
        "# Example usage\n",
        "# example_text = \"This is an example sentence for embedding.\"\n",
        "# example_embedding = get_embedding(example_text)\n",
        "\n",
        "# if example_embedding:\n",
        "#     print(\"Example embedding:\", example_embedding[:5], \"...\") # Print the first 5 elements as an example."
      ],
      "metadata": {
        "id": "naZvspu-TjVj"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_embedding = get_embedding(question)\n",
        "\n",
        "if question_embedding is None:\n",
        "    print(\"Failed to generate question embedding. Please check the question and API key.\")\n",
        "else:\n",
        "    print(\"Question embedding generated successfully.\")\n",
        "    # You can now use the question_embedding variable."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqpYu_b5UyRn",
        "outputId": "36f8788c-f639-4b0f-db87-8c3f088b5b36"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embedding for: 'How is the weather in darbhanga on Monday, 7th?'\n",
            "Question embedding generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the get_embedding function to each 'text_data' entry and store the embeddings in a new 'embedding' column.\n",
        "df['embedding'] = df['text_data'].apply(get_embedding)\n",
        "\n",
        "# Display the DataFrame with the new 'embedding' column.\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwUZ-K4dZ_0H",
        "outputId": "ac33db45-aa7c-494d-ca36-624c1df08c01"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embedding for: 'Tue 01,  Sunny,  37°/19°,  1%,  SW 9 mph, nan'\n",
            "Generating embedding for: 'Wed 02,  Mostly Cloudy,  35°/22°,  0%,  WSW 10 mph, nan'\n",
            "Generating embedding for: 'Thu 03,  Cloudy,  35°/22°,  0%,  W 11 mph, nan'\n",
            "Generating embedding for: 'Fri 04,  Mostly Sunny,  36°/21°,  1%,  W 13 mph, nan'\n",
            "Generating embedding for: 'Sat 05,  Sunny,  37°/21°,  1%,  W 11 mph, nan'\n",
            "Generating embedding for: 'Sun 06,  Sunny,  37°/23°,  1%,  SSE 7 mph, nan'\n",
            "Generating embedding for: 'Mon 07,  Sunny,  37°/25°,  2%,  ESE 13 mph, nan'\n",
            "Generating embedding for: 'Tue 08,  Mostly Sunny,  38°/24°,  4%,  E 13 mph, nan'\n",
            "Generating embedding for: 'Wed 09,  Mostly Sunny,  37°/24°,  7%,  E 10 mph, nan'\n",
            "Generating embedding for: 'Thu 10,  Mostly Sunny,  36°/23°,  17%,  E 13 mph, nan'\n",
            "Generating embedding for: 'Fri 11,  Partly Cloudy,  35°/23°,  15%,  E 13 mph, nan'\n",
            "Generating embedding for: 'Sat 12,  Isolated T-Storms,  34°/23°,  32%,  E 11 mph, nan'\n",
            "Generating embedding for: 'Sun 13,  Partly Cloudy,  34°/23°,  24%,  E 11 mph, nan'\n",
            "Generating embedding for: 'Mon 14,  Partly Cloudy,  35°/24°,  16%,  E 10 mph, nan'\n",
            "      Day            Date  Feel like  Temperature     Humidity  \\\n",
            "0  Tue 01           Sunny    37°/19°           1%     SW 9 mph   \n",
            "1  Wed 02   Mostly Cloudy    35°/22°           0%   WSW 10 mph   \n",
            "2  Thu 03          Cloudy    35°/22°           0%     W 11 mph   \n",
            "3  Fri 04    Mostly Sunny    36°/21°           1%     W 13 mph   \n",
            "4  Sat 05           Sunny    37°/21°           1%     W 11 mph   \n",
            "\n",
            "    Wind direction and speed  \\\n",
            "0                        NaN   \n",
            "1                        NaN   \n",
            "2                        NaN   \n",
            "3                        NaN   \n",
            "4                        NaN   \n",
            "\n",
            "                                           text_data  \\\n",
            "0      Tue 01,  Sunny,  37°/19°,  1%,  SW 9 mph, nan   \n",
            "1  Wed 02,  Mostly Cloudy,  35°/22°,  0%,  WSW 10...   \n",
            "2     Thu 03,  Cloudy,  35°/22°,  0%,  W 11 mph, nan   \n",
            "3  Fri 04,  Mostly Sunny,  36°/21°,  1%,  W 13 mp...   \n",
            "4      Sat 05,  Sunny,  37°/21°,  1%,  W 11 mph, nan   \n",
            "\n",
            "                                           embedding  \n",
            "0  [-0.04154503345489502, 0.013616434298455715, 0...  \n",
            "1  [-0.05264878273010254, 0.016400611028075218, 0...  \n",
            "2  [-0.043083418160676956, 0.01109634805470705, -...  \n",
            "3  [-0.03871142491698265, -0.0028530096169561148,...  \n",
            "4  [-0.024546045809984207, 0.015909474343061447, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_distance(text_emb):\n",
        "    \"\"\"\n",
        "    Calculates the dot product between a text embedding and the question embedding.\n",
        "\n",
        "    Args:\n",
        "        text_emb (list): The embedding vector for a text entry.\n",
        "\n",
        "    Returns:\n",
        "        float: The dot product, representing the similarity between the embeddings.\n",
        "    \"\"\"\n",
        "    if question_embedding is None:\n",
        "        print(\"Error: Question embedding is None. Cannot calculate distance.\")\n",
        "        return None  # Or raise an exception\n",
        "\n",
        "    # Convert embeddings to NumPy arrays for efficient dot product calculation.\n",
        "    text_emb_array = np.array(text_emb)\n",
        "    question_emb_array = np.array(question_embedding)\n",
        "\n",
        "    # Calculate and return the dot product.\n",
        "    return np.dot(text_emb_array, question_emb_array)"
      ],
      "metadata": {
        "id": "cKyF5Qx3aifa"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare embeddings and rank by similarity:\n",
        "df['distance'] = df['embedding'].apply(get_distance)\n",
        "\n",
        "# Sort the DataFrame by distance (similarity) in descending order.\n",
        "df.sort_values('distance', ascending=False, inplace=True)\n",
        "\n",
        "# Display the top 5 most similar entries.\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_xlIjaHYX75",
        "outputId": "b62fbf8c-d1a0-49d0-9f2d-997844d4accc"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Day            Date  Feel like  Temperature     Humidity  \\\n",
            "8   Wed 09    Mostly Sunny    37°/24°           7%     E 10 mph   \n",
            "6   Mon 07           Sunny    37°/25°           2%   ESE 13 mph   \n",
            "0   Tue 01           Sunny    37°/19°           1%     SW 9 mph   \n",
            "13  Mon 14   Partly Cloudy    35°/24°          16%     E 10 mph   \n",
            "7   Tue 08    Mostly Sunny    38°/24°           4%     E 13 mph   \n",
            "\n",
            "     Wind direction and speed  \\\n",
            "8                         NaN   \n",
            "6                         NaN   \n",
            "0                         NaN   \n",
            "13                        NaN   \n",
            "7                         NaN   \n",
            "\n",
            "                                            text_data  \\\n",
            "8   Wed 09,  Mostly Sunny,  37°/24°,  7%,  E 10 mp...   \n",
            "6     Mon 07,  Sunny,  37°/25°,  2%,  ESE 13 mph, nan   \n",
            "0       Tue 01,  Sunny,  37°/19°,  1%,  SW 9 mph, nan   \n",
            "13  Mon 14,  Partly Cloudy,  35°/24°,  16%,  E 10 ...   \n",
            "7   Tue 08,  Mostly Sunny,  38°/24°,  4%,  E 13 mp...   \n",
            "\n",
            "                                            embedding  distance  \n",
            "8   [-0.030070679262280464, -0.001018274575471878,...  0.408664  \n",
            "6   [-0.021476855501532555, 0.009013068862259388, ...  0.398920  \n",
            "0   [-0.04154503345489502, 0.013616434298455715, 0...  0.379579  \n",
            "13  [-0.012975481338799, 0.011263438500463963, 0.0...  0.375104  \n",
            "7   [-0.029467446729540825, -0.0020820696372538805...  0.375104  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an AI assistant that answers questions about weather using provided context.\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "        {\"role\": \"assistant\", \"content\": f\"Use this context about current weather to answer the question: {context}.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Access the response content\n",
        "answer = response.choices[0].message.content\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KhaLLlnKwhQ",
        "outputId": "e812beb6-8b39-4c0f-ac56-956e6d957395"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Darbhanga on Monday, 7th is forecasted to be sunny with a high of 37°C and a low of 25°C. There is a 2% chance of precipitation with an east-southeasterly wind at 13 mph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print top 3 sentences, based on distance - likely the answer should be derived from those sentences.\n",
        "print(df['text_data'].head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QqNQGNQiClL",
        "outputId": "cfcfb6e0-fe53-4a37-9788-cdff90efc686"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8    Wed 09,  Mostly Sunny,  37°/24°,  7%,  E 10 mp...\n",
            "6      Mon 07,  Sunny,  37°/25°,  2%,  ESE 13 mph, nan\n",
            "0        Tue 01,  Sunny,  37°/19°,  1%,  SW 9 mph, nan\n",
            "Name: text_data, dtype: object\n"
          ]
        }
      ]
    }
  ]
}